{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU openai pinecone-client langchain\n",
    "%pip install --upgrade tiktoken\n",
    "%pip install wikipedia-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL3 = \"gpt-3.5-turbo\"\n",
    "MODEL4 = \"gpt-4\"\n",
    "REFRESH = False\n",
    "LOAD = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "model_name = 'text-embedding-ada-002'\n",
    "\n",
    "embed = OpenAIEmbeddings(\n",
    "    model=model_name,\n",
    "    openai_api_key=OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peter/.local/lib/python3.10/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "\n",
    "# find API key in console at app.pinecone.io\n",
    "YOUR_API_KEY = os.environ.get(\"PINECONE_API_KEY\")\n",
    "YOUR_ENV = \"us-west1-gcp-free\"\n",
    "\n",
    "pinecone.init(api_key=YOUR_API_KEY, environment=YOUR_ENV)\n",
    "\n",
    "\n",
    "#index_name = 'langchain-retrieval-agent'\n",
    "index_name = 'retrieval-index'\n",
    "pinecone.init(\n",
    "    api_key=YOUR_API_KEY,\n",
    "    environment=YOUR_ENV\n",
    ")\n",
    "\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    print (\"we create a new index\")\n",
    "    pinecone.create_index(\n",
    "        name=index_name,\n",
    "        metric='dotproduct',\n",
    "        dimension=1536  # 1536 dim of text-embedding-ada-002\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexDescription(name='retrieval-index', metric='dotproduct', replicas=1, dimension=1536.0, shards=1, pods=1, pod_type='p1', status={'ready': True, 'state': 'Ready'}, metadata_config=None, source_collection='')\n",
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 123}},\n",
      " 'total_vector_count': 123}\n"
     ]
    }
   ],
   "source": [
    "index = pinecone.Index(index_name)\n",
    "print(pinecone.describe_index(index_name))\n",
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scratch some text data (wiki scratacher) part 1 of 2\n",
    "import wikipediaapi\n",
    "\n",
    "def get_page_text(page_title, language):\n",
    "    wiki_wiki = wikipediaapi.Wikipedia(language)\n",
    "\n",
    "    page = wiki_wiki.page(page_title)\n",
    "    if page.exists():\n",
    "        return page.text\n",
    "    else:\n",
    "        return None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "def num_tokens_from_string(string: str, model: str = \"gpt-3.5-turbo-0301\") -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to split the text into smaller chunks\n",
    "# https://python.langchain.com/en/latest/modules/indexes/text_splitters/getting_started.html\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1024,\n",
    "    chunk_overlap  = 100,\n",
    "    length_function = num_tokens_from_string,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_string_helper(input_str):\n",
    "    input_str = input_str.lower()\n",
    "    ascii_str = ''.join(char if ord(char) < 128 else 'x' for char in input_str)\n",
    "    final_str = ascii_str[:8]\n",
    "    return final_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD:\n",
    "    #scratch some text data (get data) part 2 of 2\n",
    "    language = \"pl\"  \n",
    "    for page_titel in [\"Warszawa\", \"Kraków\", \"Mikołaj_Kopernik\"]: # load examples from wiki pages as knowwladge DB\n",
    "        page_txt = get_page_text(page_titel, language)\n",
    "        if page_txt:\n",
    "            print(f\"Processing {page_titel} page...\")\n",
    "            texts = text_splitter.create_documents([page_txt])\n",
    "            # add to local brain and embedings to picone\n",
    "            id = 0\n",
    "            for chunk in texts:\n",
    "                embeds = embed.embed_documents([chunk.page_content])\n",
    "                chunk_id = f\"{convert_string_helper(page_titel)}_{id:06d}\"\n",
    "                metadatas = {\n",
    "                    'title': page_titel,\n",
    "                    'text': chunk.page_content\n",
    "                } \n",
    "                to_upsert = (chunk_id, embeds, metadatas)\n",
    "                #print (to_upsert)\n",
    "                upsert_response = index.upsert(\n",
    "                    vectors=[to_upsert],\n",
    "                )\n",
    "                print(f\"Processed chunk {chunk_id} for {page_titel}\")\n",
    "                id += 1\n",
    "        else:\n",
    "            print(f\"Page {page_titel} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "text_field = \"text\"\n",
    "\n",
    "# switch back to normal index for langchain\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "vectorstore = Pinecone(\n",
    "    index, embed.embed_query, text_field\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test similarity search\n",
    "#query = \"Pierwszymi osadami powstałymi w obecnych granicach administracyjnych Warszawy były\"\n",
    "query = \"Jakie osady powstały w granicach Warszawy?\"\n",
    "#query = \"XXXX\"\n",
    "\n",
    "results = vectorstore.similarity_search(\n",
    "    query,  # our search query\n",
    "    k=3  # return 3 most relevant docs\n",
    ")\n",
    "for result in results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test query\n",
    "for query_txt in [\n",
    "    \"Pierwszymi osadami powstałymi w obecnych granicach administracyjnych Warszawy były\",\n",
    "    \"Jakie osady powstały w granicach Warszawy?\",\n",
    "    \"XXXX\"    \n",
    "]:\n",
    "    #embeds = [record['embedding'] for record in (get_embeddings([query_txt]))['data']][0]\n",
    "    embeds = embed.embed_documents([query_txt])\n",
    "    query_response = index.query(\n",
    "        top_k=3,\n",
    "        include_values=True,\n",
    "        include_metadata=False,\n",
    "        vector=embeds\n",
    "    )[\"matches\"]\n",
    "    print(f\"text: {query_txt}\")\n",
    "    for item in query_response:\n",
    "        print(f\"id: {item.id}, score: {item.score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# chat completion llm\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    temperature=0.0\n",
    ")\n",
    "# conversational memory\n",
    "conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key='chat_history',\n",
    "    k=5,\n",
    "    return_messages=True\n",
    ")\n",
    "# retrieval qa chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pierwszymi osadami powstałymi w granicach administracyjnych Warszawy były: Bródno (IX/X wiek), Kamion (II połowa XI wieku), Solec (XI wiek) i Jazdów (XIII wiek).'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Jakie osady powstały w granicach Warszawy?\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nie jest jasne, o który okres w życiu Mikołaja Kopernika pytasz. W tekście znajdują się informacje na temat różnych dziedzin, w których działał, takich jak astronomia, ekonomia, medycyna, a także jego edukacja i młodość. Proszę sprecyzować swoje pytanie.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(\"Co robil mikolaj?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name='Knowledge Base',\n",
    "        func=qa.run,\n",
    "        description=(\n",
    "            'use this tool when answering general knowledge queries to get '\n",
    "            'more information about the topic'\n",
    "        )\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "agent = initialize_agent(\n",
    "    agent='chat-conversational-react-description',\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    early_stopping_method='generate',\n",
    "    memory=conversational_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Knowledge Base\",\n",
      "    \"action_input\": \"What do Warsaw and Krakow have in common?\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mWarsaw and Krakow are both cities in Poland.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Warsaw and Krakow are both cities in Poland.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Czy Warszawa i Krakow maja cos wspolnego',\n",
       " 'chat_history': [],\n",
       " 'output': 'Warsaw and Krakow are both cities in Poland.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"Czy Warszawa i Krakow maja cos wspolnego\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Knowledge Base\",\n",
      "    \"action_input\": \"Mikołaj Kopernik place of residence\"\n",
      "}\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d5cb59605111c3124eb2b5af4c16e218 in your message.).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mMikołaj Kopernik was born and lived in Toruń, Poland. Later in life, he spent a significant amount of time in Lidzbark Warmiński and Frombork.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Mikołaj Kopernik was born and lived in Toruń, Poland. Later in life, he spent a significant amount of time in Lidzbark Warmiński and Frombork.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Gdzie mieszkal Mikolaj?',\n",
       " 'chat_history': [HumanMessage(content='Czy Warszawa i Krakow maja cos wspolnego', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='Warsaw and Krakow are both cities in Poland.', additional_kwargs={}, example=False)],\n",
       " 'output': 'Mikołaj Kopernik was born and lived in Toruń, Poland. Later in life, he spent a significant amount of time in Lidzbark Warmiński and Frombork.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"Gdzie mieszkal Mikolaj?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Un, deux, trois, quatre, cinq\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Licz do 5 po francusku',\n",
       " 'chat_history': [HumanMessage(content='Czy Warszawa i Krakow maja cos wspolnego', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='Warsaw and Krakow are both cities in Poland.', additional_kwargs={}, example=False),\n",
       "  HumanMessage(content='Gdzie mieszkal Mikolaj?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='Mikołaj Kopernik was born and lived in Toruń, Poland. Later in life, he spent a significant amount of time in Lidzbark Warmiński and Frombork.', additional_kwargs={}, example=False)],\n",
       " 'output': 'Un, deux, trois, quatre, cinq'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"Licz do 5 po francusku\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
