import sys
import os
import time
import logging
import json
import requests
from requests.exceptions import RequestException, Timeout
import openai

# Use AI-Devs GPT4 Proxy?
PROXY = False

MODEL="gpt-3.5-turbo"
MODEL="gpt-4"

HEADERS = {
    "User-Agent": "Mozilla/5.0 (X11; Linux x86_64; rv:10.0) Gecko/20100101 Firefox/10.0 (PfV)"
}
TDELTA = 30 # every new attempt to read will get 30 seconds more

def fetch_url_content(url, headers=HEADERS, timeout=1, retries=1):
    for attempt in range(retries):
        try:
            response = requests.get(url, headers=HEADERS, timeout=timeout)
            response.raise_for_status()  # Raise an exception for HTTP errors

            return response.text

        except Timeout:
            timeout += TDELTA
            print(f"Timeout {timeout} occurred during attempt {attempt + 1}. Retrying...")
            if attempt == retries - 1:
                raise Timeout("The maximum number of retries has been reached. Operation timed out.")

        except RequestException as e:
            print(f"An error occurred during attempt {attempt + 1}: {e}")
            if attempt == retries - 1:
                raise RequestException(f"The maximum number of retries has been reached. Last error: {e}")

# Prompt definition
# compatible with gpt-3.5-turbo, do not stick to jason formatting of the answer.
# request to split the gpt response to chapters divided by ### characters
# conduct split of the gpt response into the expected list in python together with some simple syntax checking

# openAI SYSTEM
system_text = """
Based on your DATABASE answer user questions in less than 200 characters. Answer in Polish.

### DATABASE

"""

# openAI user text, the rest wll be concatenated based on the task's request
user_text = ""


def chat_completion(system_text, user_text):
    """
    This function takes two arguments, 'system_text' and 'user_text', and generates a response using the OpenAI ChatCompletion API.

    Args:
    system_text (str): A string containing the system message to set the context for the conversation.
    user_text (str): A string containing the user message to which the function will generate a response.

    Returns:
    str: A message generated by the GPT-3.5-turbo model based on the input messages.

    Example usage:
    >>> system_text = "You are an AI language model."
    >>> user_text = "How does GPT-3.5-turbo work?"
    >>> response = chat_completion(system_text, user_text)
    >>> print(response)
    "GPT-3.5-turbo is a cutting-edge AI model that generates human-like text based on context and input. It works by predicting the next word in a sequence, using deep learning techniques and a vast training dataset."
    """
    response = openai.ChatCompletion.create(
        model=MODEL,
        messages=[
            {"role": "system", "content": system_text},
            {"role": "user", "content": user_text},
        ],
    )
    message = response["choices"][0]["message"]["content"]
    return message


def gpt4_completion(system_text, user_text):
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {PROXY_API_KEY}",
    }
    data = {
        "model": "gpt-4",
        "messages": [
            {"role": "system", "content": system_text},
            {"role": "user", "content": user_text},
        ],
        "temperature": 0.7,
    }
    response = requests.post(PROXY_API_URL, headers=headers, data=json.dumps(data))
    json_response = response.json()
    logging.debug("Response from GPT4 AI-Devs: %s", json_response)
    message = json_response["choices"][0]["message"]["content"]
    return message

if __name__ == "__main__":
    if len(sys.argv) > 1:
        DEBUG_MODE = sys.argv[1]
    else:
        # DEBUG_MODE = "debug", "info", anything else for off
        DEBUG_MODE = "off"
    if DEBUG_MODE == "debug":
        logging.basicConfig(
            level=logging.DEBUG, format="%(asctime)s - %(levelname)s - %(message)s"
        )
    elif DEBUG_MODE == "info":
        logging.basicConfig(
            level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
        )
    else:
        logging.disable(sys.maxsize)

    TASKNAME = os.path.splitext(os.path.basename(__file__))[0]
    KEY = os.environ.get("AIDEVS")
    OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
    URL_AI_DEVS = os.environ.get("URL_AI_DEVS")

    # AI-Devs proxy settings
    PROXY_API_URL = os.environ.get("PROXY_API_URL")
    PROXY_API_KEY = os.environ.get("PROXY_API_KEY")

    TOKEN = "/token/"
    TASK = "/task/"
    ANSWER = "/answer/"

    if not KEY:
        raise ValueError("API KEY cannot be empty, setup environment variable AIDEVS")
    if not OPENAI_API_KEY:
        raise ValueError(
            "openAI API KEY cannot be empty, setup environment variable OPENAI_API_KEY"
        )
    if not URL_AI_DEVS:
        raise ValueError(
            "URL for AI_devs cannot be empty, setup environment variable URL_AI_DEVS"
        )
    if not PROXY_API_URL:
        raise ValueError(
            "URL for AI_devs GPT4 Proxy cannot be empty, setup environment variable PROXY_API_URL"
        )
    if not PROXY_API_KEY:
        raise ValueError(
            "URL for AI_devs GPT4 Proxy cannot be empty, setup environment variable PROXY_API_KEY"
        )

    logging.debug("Key:%s; TaskName:%s", KEY, TASKNAME)

    openai.api_key = OPENAI_API_KEY

    data = {
        "apikey": f"{KEY}",
    }

    response = requests.post(URL_AI_DEVS + TOKEN + TASKNAME, json=data)
    json_response = response.json()
    logging.info("Received json: %s", json_response)

    token = json_response.get("token")
    response = requests.get(URL_AI_DEVS + TASK + token)
    json_response = response.json()
    logging.info("Received json: %s", json_response)

    url = json_response.get("input")
    user_text = json_response.get("question")

    content = None
    try:
        content = fetch_url_content(url, timeout=60, retries=5)
    except Exception as e:
        print(f"An error occurred while fetching the URL content: {e}")
        sys.exit(1)
    system_text += content

    logging.info("QUESTION: %s", user_text)
    logging.info("DATABASE: \n%s", content)

    logging.info("Using %s", "AI-Devs GPT4" if PROXY else f"openAI {MODEL}")
   
    start_time = time.time()
    if PROXY:
        answer = gpt4_completion(system_text, user_text)
    else:
        answer = chat_completion(system_text, user_text)
    end_time = time.time()
    duration = end_time - start_time
    logging.info("Done after %s seconds", "{:.0f}".format(duration))
    logging.info("Answer to be sent: %s", answer)
    data = {"answer": answer}

    #sys.exit(1)
    response = requests.post(URL_AI_DEVS + ANSWER + token, json=data)
    json_response = response.json()
    print(json_response)

